{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1a487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e54e96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        \n",
    "        self.prototype = None\n",
    "        \n",
    "        self.column = None\n",
    "        self.threshold = None\n",
    "        \n",
    "        self.probas = None\n",
    "        self.depth = None\n",
    "        \n",
    "        self.is_terminal = False\n",
    "        self.model = None\n",
    "        \n",
    "class PrototypeTreeClassifier:\n",
    "    def __init__(self,\n",
    "                train_features,\n",
    "                 feature_types = [\"min\", \"max\", \"mean\"], \n",
    "                 max_depth = 3, \n",
    "                 min_samples_leaf = 1, \n",
    "                 min_samples_split = 2, \n",
    "                 prototype_count = 1,\n",
    "                 use_prototype_learner=True,\n",
    "                 early_stopping_round = 3):\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.prototype_count = prototype_count\n",
    "        self.feature_types = feature_types\n",
    "        self.train_features = train_features\n",
    "        self.use_prototype_learner = use_prototype_learner\n",
    "        self.Tree = None\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        \n",
    "    def prototype(self, bags, features, labels, prototype_count):\n",
    "        number_of_rows = features.shape[0]\n",
    "        random_indices = np.random.choice(number_of_rows, \n",
    "                                          size=prototype_count, \n",
    "                                          replace=False)\n",
    "\n",
    "        prot = features[random_indices, :]\n",
    "        if len(prot.shape) == 1:\n",
    "            prot = prot.reshape(1, prot.shape[0])\n",
    "        return prot\n",
    "\n",
    "    def nodeProbas(self, y):\n",
    "        # for each unique label calculate the probability for it\n",
    "        probas = []\n",
    "\n",
    "        for one_class in self.classes:\n",
    "            proba = y[y == one_class].shape[0] / y.shape[0]\n",
    "            probas.append(proba)\n",
    "        \n",
    "        \n",
    "        return np.asarray(probas)\n",
    "\n",
    "    def features_via_prototype(self, feature_types, features, bag_ids, prototypes):\n",
    "        distances = self.calculate_distances(features, prototypes)\n",
    "        \n",
    "        bin_count  = np.unique(bag_ids, return_counts=True)[1]\n",
    "        _, index  = np.unique(bag_ids, return_index=True)\n",
    "\n",
    "        feature_list = []\n",
    "        for i in range(0, prototypes.shape[0]):\n",
    "            if \"max\" in feature_types:\n",
    "                group_max = np.maximum.reduceat(distances[:, i], index)\n",
    "                max_vals = np.repeat(group_max, bin_count)\n",
    "                feature_list.append(max_vals)\n",
    "\n",
    "            if \"min\" in feature_types:\n",
    "                group_min = np.minimum.reduceat(distances[:, i], index)\n",
    "                min_vals = np.repeat(group_min, bin_count)\n",
    "                feature_list.append(min_vals)\n",
    "\n",
    "            if \"mean\" in feature_types:\n",
    "                group_mean = np.add.reduceat(distances[:, i], index)\n",
    "                mean_vals = np.repeat(group_mean/bin_count, bin_count)\n",
    "                feature_list.append(mean_vals)\n",
    "        \n",
    "        return np.array(np.transpose(feature_list))\n",
    "\n",
    "    def dist1d(self, features, prototypes, distance_type=\"l2\"):\n",
    "        if distance_type == \"l2\":\n",
    "\n",
    "            distance = np.linalg.norm(features - prototypes, axis=1)\n",
    "        elif distance_type == \"l1\":\n",
    "            distance = np.abs(features - prototypes)\n",
    "            distance = np.sum(distance, axis=1)\n",
    "\n",
    "        return distance\n",
    "\n",
    "    def calculate_distances(self, features, prototypes):\n",
    "        feature_list = []\n",
    "        \n",
    "        for i in range(0, prototypes.shape[0]):\n",
    "            data = self.dist1d(features, prototypes[i], distance_type=\"l2\")\n",
    "            feature_list.append(data)\n",
    "        data = np.column_stack(feature_list)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def calcBestSplit(self, features, features_via_prototype, labels, bag_ids):\n",
    "        ids, index  = np.unique(bag_ids, return_index=True)\n",
    "        \n",
    "        log_reg = LogisticRegression(random_state=42)\n",
    "        model = log_reg.fit(features_via_prototype[index], labels[index])\n",
    "        \n",
    "        if len(np.unique(labels)) == 1:\n",
    "            model = None\n",
    "        \n",
    "        predictions = model.predict(features_via_prototype)\n",
    "                \n",
    "        features_left = features[predictions == 0]\n",
    "        features_right = features[predictions == 1]\n",
    "\n",
    "        labels_left = labels[predictions == 0]\n",
    "        labels_right = labels[predictions == 1]\n",
    "\n",
    "        bag_ids_left = bag_ids[predictions == 0]\n",
    "        bag_ids_right = bag_ids[predictions == 1]\n",
    "\n",
    "        return model, features_left, features_right, labels_left, labels_right, bag_ids_left, bag_ids_right\n",
    "\n",
    "    def buildDT(self, features, labels, bag_ids, node):\n",
    "            '''\n",
    "            Recursively builds decision tree from the top to bottom\n",
    "            '''\n",
    "            # checking for the terminal conditions\n",
    "\n",
    "            if node.depth >= self.max_depth:\n",
    "                node.is_terminal = True\n",
    "                return\n",
    "\n",
    "            if len(np.unique(bag_ids)) < self.min_samples_split:\n",
    "                node.is_terminal = True\n",
    "                return\n",
    "\n",
    "            if np.unique(labels).shape[0] == 1:\n",
    "                node.is_terminal = True\n",
    "                return\n",
    "            \n",
    "            node.prototype = self.prototype(bag_ids, features, labels, self.prototype_count)\n",
    "            features_updated = self.features_via_prototype(self.feature_types, features, bag_ids, node.prototype)\n",
    "            \n",
    "            # calculating current split\n",
    "            (model,\n",
    "             features_left, \n",
    "             features_right, \n",
    "             labels_left, \n",
    "             labels_right, \n",
    "             bag_ids_left, \n",
    "             bag_ids_right) = self.calcBestSplit(features, \n",
    "                                                 features_updated, \n",
    "                                                 labels, \n",
    "                                                 bag_ids)\n",
    "            \n",
    "            if model is None:\n",
    "                node.is_terminal = True\n",
    "                return\n",
    "\n",
    "            if len(np.unique(bag_ids_left)) < self.min_samples_leaf or len(np.unique(bag_ids_right)) < self.min_samples_leaf:\n",
    "                node.is_terminal = True\n",
    "                return\n",
    "            \n",
    "            node.model = model\n",
    "            \n",
    "            _, index_left  = np.unique(bag_ids_left, return_index=True)\n",
    "            _, index_right  = np.unique(bag_ids_right, return_index=True)\n",
    "            \n",
    "            # creating left and right child nodes\n",
    "            node.left = Node()\n",
    "            node.left.depth = node.depth + 1\n",
    "            node.left.probas = self.nodeProbas(labels_left[index_left])\n",
    "\n",
    "            node.right = Node()\n",
    "            node.right.depth = node.depth + 1\n",
    "            node.right.probas = self.nodeProbas(labels_right[index_right])\n",
    "\n",
    "            # splitting recursively\n",
    "            \n",
    "            self.buildDT(features_right, labels_right, bag_ids_right, node.right)\n",
    "            self.buildDT(features_left, labels_left, bag_ids_left, node.left)\n",
    "\n",
    "    def fit(self, features, labels, bag_ids):\n",
    "        '''\n",
    "        Standard fit function to run all the model training\n",
    "        '''\n",
    "        self.classes = np.unique(labels)\n",
    "\n",
    "        self.Tree = Node()\n",
    "        self.Tree.depth = 1\n",
    "        \n",
    "        self.buildDT(features, labels, bag_ids, self.Tree)\n",
    "\n",
    "    def predictSample(self, features, bag_ids, node):\n",
    "        '''\n",
    "        Passes one object through decision tree and return the probability of it to belong to each class\n",
    "        '''\n",
    "\n",
    "        # if we have reached the terminal node of the tree\n",
    "        #if node.is_terminal:\n",
    "        #    if node.model:\n",
    "        #        return node.model.predict(features_updated)\n",
    "        #    else:\n",
    "        #        return node.probas\n",
    "        if node.is_terminal:\n",
    "            return node.probas\n",
    "\n",
    "        features_updated = self.features_via_prototype(self.feature_types, features, bag_ids, node.prototype)\n",
    "        \n",
    "        if node.is_terminal:\n",
    "            return node.model.predict(features_updated)\n",
    "\n",
    "        predictions = node.model.predict(features_updated)\n",
    "        \n",
    "        if predictions[0] == 1:\n",
    "            probas = self.predictSample(features, bag_ids, node.right)\n",
    "        else:\n",
    "            probas = self.predictSample(features, bag_ids, node.left)\n",
    "\n",
    "        return probas\n",
    "\n",
    "    def predict(self, features, bag_ids):\n",
    "        '''\n",
    "        Returns the labels for each X\n",
    "        '''\n",
    "\n",
    "        if type(features) == pd.DataFrame:\n",
    "            X = np.asarray(features)\n",
    "\n",
    "        sort_index = np.argsort(bag_ids)\n",
    "        bag_ids = bag_ids[sort_index]\n",
    "        features = features[sort_index]\n",
    "\n",
    "        features_updated = self.features_via_prototype(self.feature_types, features, bag_ids, self.Tree.prototype)\n",
    "\n",
    "        index  = np.unique(bag_ids, return_index=True)[1]\n",
    "        count  = np.unique(bag_ids, return_counts=True)[1]\n",
    "        index = np.append(index, bag_ids.shape[0])   \n",
    "        predictions = []\n",
    "\n",
    "        for i in range(0, len(index) - 1):\n",
    "            pred = np.argmax(self.predictSample(features[index[i]:index[i+1]], \n",
    "                                                bag_ids[index[i]:index[i+1]], \n",
    "                                                self.Tree))\n",
    "            pred = np.repeat(pred, count[i])\n",
    "            predictions = np.concatenate((predictions, pred), axis=0)\n",
    "\n",
    "        return np.asarray(predictions)\n",
    "\n",
    "\n",
    "def split_features_labels_bags(data):\n",
    "    features = data[data.columns[~data.columns.isin([0, 1])]].to_numpy()\n",
    "    labels = data[0].to_numpy()\n",
    "    bag_ids = data[1].to_numpy()\n",
    "\n",
    "    #sort_index = np.argsort(bag_ids)\n",
    "    #bag_ids = bag_ids[sort_index]\n",
    "    #features = features[sort_index]\n",
    "    \n",
    "    return (features, labels, bag_ids)\n",
    "\n",
    "def train_test_split(dataset, rep, fold, explained_variance, fit_on_full = False, custom=False):\n",
    "    data = pd.read_csv(f\"./datasets/{dataset}.csv\", header=None)\n",
    "    testbags =  pd.read_csv(f\"./datasets/{dataset}.csv_rep{rep}_fold{fold}.txt\", header=None)\n",
    "    \n",
    "    if custom:\n",
    "        min_limit = testbags.min()[0]\n",
    "        max_limit = testbags.max()[0]\n",
    "        size = testbags.size\n",
    "        size_pos = size // 2\n",
    "        pos = list(range(min_limit, min_limit + size_pos))\n",
    "        neg = list(range(max_limit - size_pos + 1, max_limit + 1))\n",
    "        testbags = pd.DataFrame([*pos, *neg])\n",
    "          \n",
    "    train_data = data[~data[1].isin(testbags[0].tolist())]    \n",
    "    test_data = data[data[1].isin(testbags[0].tolist())]\n",
    "    \n",
    "    (train_features, train_labels, train_bag_ids) = split_features_labels_bags(train_data)\n",
    "    (test_features, test_labels, test_bag_ids) = split_features_labels_bags(test_data)\n",
    "    \n",
    "    if explained_variance < 1:\n",
    "        pipe = Pipeline([('pca', PCA(n_components = explained_variance, \n",
    "                         svd_solver = \"full\")), \n",
    "         ('scaler', StandardScaler()), ])\n",
    "    else:\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), ])\n",
    "    \n",
    "    if fit_on_full:\n",
    "        pipe.fit(data[data.columns[~data.columns.isin([0,1])]].to_numpy())\n",
    "    else:\n",
    "        pipe.fit(train_features)\n",
    "\n",
    "    train_features = pipe.transform(train_features)\n",
    "    test_features = pipe.transform(test_features)\n",
    "    \n",
    "    return (\n",
    "        train_features, \n",
    "        train_labels, \n",
    "        train_bag_ids,\n",
    "        test_features, \n",
    "        test_labels,\n",
    "        test_bag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5e8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Musk1\"\n",
    "\n",
    "i = 1\n",
    "j = 1\n",
    "\n",
    "(train_features,\n",
    "     train_labels,\n",
    "     train_bag_ids,\n",
    "     test_features,\n",
    "     test_labels,\n",
    "     test_bag_ids) = train_test_split(dataset, i, j, 1, fit_on_full = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cb81cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = [[0.00001, 0.05], [0.00001, 0.05],[0.00001, 0.05], [0.00001, 0.05], [0.00001, 0.05], [1],[1]]\n",
    "\n",
    "model = PrototypeForest(size=1,\n",
    "                        max_depth=3,\n",
    "                        min_samples_leaf=2,\n",
    "                        min_samples_split=4,\n",
    "                        prototype_count=1,\n",
    "                        early_stopping_round= 5,\n",
    "                        use_prototype_learner = True)\n",
    "\n",
    "model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "_, index  = np.unique(test_bag_ids, return_index=True)\n",
    "\n",
    "score = roc_auc_score(test_labels[index], probas[index])\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Score is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1048a047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = PrototypeTreeClassifier(\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=4,\n",
    "    prototype_count=1,\n",
    "    early_stopping_round= 5,\n",
    "    use_prototype_learner = False,\n",
    "    train_features = train_features\n",
    ")\n",
    "\n",
    "model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "# model.score(features_via_prototype[index], labels[index])\n",
    "\n",
    "probas = model.predict(test_features, test_bag_ids)\n",
    "\n",
    "_, index  = np.unique(test_bag_ids, return_index=True)\n",
    "\n",
    "score = roc_auc_score(test_labels[index], probas[index])\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73836848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypeForest:\n",
    "    def __init__(self, size,\n",
    "                feature_types = [\"min\", \"mean\", \"max\"],\n",
    "                max_depth = 8, \n",
    "                min_samples_leaf = 2, \n",
    "                min_samples_split = 2, \n",
    "                prototype_count = 1,\n",
    "                use_prototype_learner = True,\n",
    "                early_stopping_round = 10):\n",
    "        self.size = size\n",
    "        self._trees = []\n",
    "        self._tuning_trees = []\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.prototype_count = prototype_count\n",
    "        self.use_prototype_learner = use_prototype_learner\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        \n",
    "    def sample(self, features, labels, bag_ids):\n",
    "        ids, index  = np.unique(bag_ids, return_index=True)\n",
    "        group_min = np.minimum.reduceat(labels, index)\n",
    "        pos_bag_size = math.ceil(np.where(group_min == 1)[0].shape[0] * 0.8)\n",
    "        neg_bag_size = math.ceil(np.where(group_min == 0)[0].shape[0] * 0.8)\n",
    "        \n",
    "        bags_pos = np.random.choice(ids[np.where(group_min == 1)], pos_bag_size, replace=False)\n",
    "        bags_neg = np.random.choice(ids[np.where(group_min == 0)], neg_bag_size, replace=False)\n",
    "        \n",
    "        df = pd.DataFrame(np.concatenate([train_bag_ids.reshape(train_bag_ids.shape[0],1),\n",
    "                                          train_labels.reshape(train_labels.shape[0],1)],\n",
    "                                         axis=1))\n",
    "        indices_pos = df[df[0].isin(bags_pos)].index.to_numpy()\n",
    "        indices_neg = df[df[0].isin(bags_neg)].index.to_numpy()\n",
    "        inbag_indices = np.concatenate((indices_pos, indices_neg))\n",
    "        oo_bag_mask = np.ones(labels.shape[0], dtype=bool)\n",
    "        oo_bag_mask[inbag_indices] = False\n",
    "        outbag_indices = np.where(oo_bag_mask == 1)\n",
    "        \n",
    "        return inbag_indices, outbag_indices\n",
    "    \n",
    "    def fit(self, features, labels, bag_ids):\n",
    "        for i in range(self.size):\n",
    "            if (self.use_prototype_learner) & (i%10==1):\n",
    "                print(f\"Tree {i} will be trained\")\n",
    "            \n",
    "            (inbag_indices, _) = self.sample(features, labels, bag_ids)\n",
    "            inbag_features = features[inbag_indices]\n",
    "            inbag_labels = labels[inbag_indices]\n",
    "            inbag_bag_ids = bag_ids[inbag_indices]\n",
    "            tree = PrototypeTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                prototype_count = self.prototype_count,\n",
    "                use_prototype_learner = self.use_prototype_learner,\n",
    "                train_features = inbag_features,\n",
    "                early_stopping_round = self.early_stopping_round\n",
    "            )\n",
    "            tree.fit(inbag_features, inbag_labels, inbag_bag_ids)\n",
    "            self._trees.append(tree)\n",
    "            \n",
    "    def predict(self, features, bag_ids):\n",
    "        temp = [t.predict(features, bag_ids) for t in self._trees]\n",
    "        preds = np.transpose(np.array(temp))\n",
    "        return mode(preds,1)[0]\n",
    "    \n",
    "    def predict_proba(self, features, bag_ids):\n",
    "        temp = [t.predict(features, bag_ids) for t in self._trees]\n",
    "        preds = np.transpose(np.array(temp))\n",
    "        return np.sum(preds==1, axis=1)/self.size\n",
    "\n",
    "def generate_random(lower, upper):\n",
    "    random_number = random.random()\n",
    "    random_number = random_number + lower\n",
    "    random_range = upper - lower\n",
    "    random_number = random_number*random_range\n",
    "    return random_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dec937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Musk1\"\n",
    "\n",
    "(train_features,\n",
    "     train_labels,\n",
    "     train_bag_ids,\n",
    "     test_features,\n",
    "     test_labels,\n",
    "     test_bag_ids) = train_test_split(dataset, i, j, 1, fit_on_full = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70c0724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = PrototypeForest(size=30,\n",
    "                        max_depth=4,\n",
    "                        min_samples_leaf=2,\n",
    "                        min_samples_split=4,\n",
    "                        prototype_count=1,\n",
    "                        early_stopping_round= 5,\n",
    "                        use_prototype_learner = False)\n",
    "\n",
    "model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "_, index  = np.unique(test_bag_ids, return_index=True)\n",
    "\n",
    "score = roc_auc_score(test_labels[index], probas[index])\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Score is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5871c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best size is 100 and best depth is 8 and best var is 1.0 for dataset CorelHorses\n",
      "Rep 1, fold 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    for j in range(1, 11):\n",
    "        print(f\"Rep {i}, fold {j}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        (train_features,\n",
    "             train_labels,\n",
    "             train_bag_ids,\n",
    "             test_features,\n",
    "             test_labels,\n",
    "             test_bag_ids) = train_test_split(dataset, i, j, best_var, fit_on_full = True)\n",
    "\n",
    "        model = PrototypeForest(size=best_size,\n",
    "                                max_depth=best_depth,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_samples_split=4,\n",
    "                                prototype_count=1,\n",
    "                                early_stopping_round= 5,\n",
    "                                use_prototype_learner = False)\n",
    "\n",
    "        model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "        probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "        _, index  = np.unique(test_bag_ids, return_index=True)\n",
    "\n",
    "        score = roc_auc_score(test_labels[index], probas[index])\n",
    "        end_time = time.time()\n",
    "        info_list_row = [dataset, i, j, best_size, best_depth, best_var, score, end_time - start_time]\n",
    "        info_list.append(info_list_row)\n",
    "        all_accuracy.append(score)\n",
    "        print(f\"Score is {score}\")\n",
    "\n",
    "print(f\"Accuracy for {dataset} is {sum(all_accuracy)/len(all_accuracy)}\")\n",
    "perf_df = pd.DataFrame(info_list, columns=[\"dataset\", \"rep\", \"fold\", \"best_size\", \"best_depth\", \"best_var\",  \"auc\", \"time\"])\n",
    "perf_df.to_csv(f\"./performance_linear/{dataset}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7aa123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1809131 , -0.88252743, -0.43062779, ..., -0.17946317,\n",
       "         0.55638614, -0.06861517],\n",
       "       [ 0.1809131 , -0.80318093, -0.90819777, ..., -0.17946317,\n",
       "         0.53912936, -0.06861517],\n",
       "       [ 0.1809131 , -0.80318093, -0.90819777, ..., -0.17946317,\n",
       "         0.53912936, -0.05014186],\n",
       "       ...,\n",
       "       [ 0.2362567 ,  0.20565318,  0.85736399, ..., -0.17946317,\n",
       "         0.12496664, -1.28785397],\n",
       "       [ 0.01488231,  0.70440263,  1.53753942, ...,  0.38295103,\n",
       "         0.5046158 ,  0.74421069],\n",
       "       [ 0.73434907, -0.0097159 ,  0.79947672, ...,  1.25781757,\n",
       "         0.65992682,  1.15062363]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04d0caaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erdemb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "fitted = log_reg.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d153da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = fitted.predict(train_features)\n",
    "check = np.c_[train_features, predicted]\n",
    "check[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8576e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = np.c_[train_features, predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "319837ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1809131 , -0.88252743, -0.43062779, ..., -0.17946317,\n",
       "         0.55638614, -0.06861517],\n",
       "       [ 0.1809131 , -0.80318093, -0.90819777, ..., -0.17946317,\n",
       "         0.53912936, -0.06861517],\n",
       "       [ 0.1809131 , -0.80318093, -0.90819777, ..., -0.17946317,\n",
       "         0.53912936, -0.05014186],\n",
       "       ...,\n",
       "       [ 0.2362567 ,  0.20565318,  0.85736399, ..., -0.17946317,\n",
       "         0.12496664, -1.28785397],\n",
       "       [ 0.01488231,  0.70440263,  1.53753942, ...,  0.38295103,\n",
       "         0.5046158 ,  0.74421069],\n",
       "       [ 0.73434907, -0.0097159 ,  0.79947672, ...,  1.25781757,\n",
       "         0.65992682,  1.15062363]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ae50717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep 1, fold 1\n",
      "Score is 0.75\n",
      "Rep 1, fold 2\n",
      "Score is 0.9285714285714286\n",
      "Rep 1, fold 3\n",
      "Score is 0.8541666666666666\n",
      "Rep 1, fold 4\n",
      "Score is 0.75\n",
      "Rep 1, fold 5\n",
      "Score is 0.9791666666666666\n",
      "Rep 1, fold 6\n",
      "Score is 1.0\n",
      "Rep 1, fold 7\n",
      "Score is 0.9375\n",
      "Rep 1, fold 8\n",
      "Score is 0.8125\n",
      "Rep 1, fold 9\n",
      "Score is 0.8125\n",
      "Rep 1, fold 10\n",
      "Score is 0.7857142857142857\n",
      "Rep 2, fold 1\n",
      "Score is 0.9107142857142858\n",
      "Rep 2, fold 2\n",
      "Score is 0.875\n",
      "Rep 2, fold 3\n",
      "Score is 0.7916666666666666\n",
      "Rep 2, fold 4\n",
      "Score is 0.7916666666666667\n",
      "Rep 2, fold 5\n",
      "Score is 0.7291666666666667\n",
      "Rep 2, fold 6\n",
      "Score is 1.0\n",
      "Rep 2, fold 7\n",
      "Score is 0.7083333333333334\n",
      "Rep 2, fold 8\n",
      "Score is 0.7708333333333334\n",
      "Rep 2, fold 9\n",
      "Score is 0.8958333333333334\n",
      "Rep 2, fold 10\n",
      "Score is 0.9761904761904763\n",
      "Rep 3, fold 1\n",
      "Score is 0.8928571428571428\n",
      "Rep 3, fold 2\n",
      "Score is 0.75\n",
      "Rep 3, fold 3\n",
      "Score is 0.7083333333333334\n",
      "Rep 3, fold 4\n",
      "Score is 0.7083333333333333\n",
      "Rep 3, fold 5\n",
      "Score is 0.5625\n",
      "Rep 3, fold 6\n",
      "Score is 1.0\n",
      "Rep 3, fold 7\n",
      "Score is 0.6666666666666666\n",
      "Rep 3, fold 8\n",
      "Score is 0.9583333333333334\n",
      "Rep 3, fold 9\n",
      "Score is 1.0\n",
      "Rep 3, fold 10\n",
      "Score is 0.8571428571428572\n",
      "Rep 4, fold 1\n",
      "Score is 0.8035714285714286\n",
      "Rep 4, fold 2\n",
      "Score is 0.9107142857142858\n",
      "Rep 4, fold 3\n",
      "Score is 1.0\n",
      "Rep 4, fold 4\n",
      "Score is 0.8333333333333334\n",
      "Rep 4, fold 5\n",
      "Score is 0.7916666666666666\n",
      "Rep 4, fold 6\n",
      "Score is 0.6666666666666667\n",
      "Rep 4, fold 7\n",
      "Score is 0.8333333333333334\n",
      "Rep 4, fold 8\n",
      "Score is 0.625\n",
      "Rep 4, fold 9\n",
      "Score is 0.875\n",
      "Rep 4, fold 10\n",
      "Score is 0.9285714285714285\n",
      "Rep 5, fold 1\n",
      "Score is 0.75\n",
      "Rep 5, fold 2\n",
      "Score is 0.875\n",
      "Rep 5, fold 3\n",
      "Score is 0.9166666666666667\n",
      "Rep 5, fold 4\n",
      "Score is 0.75\n",
      "Rep 5, fold 5\n",
      "Score is 0.9166666666666667\n",
      "Rep 5, fold 6\n",
      "Score is 0.9166666666666667\n",
      "Rep 5, fold 7\n",
      "Score is 0.9583333333333334\n",
      "Rep 5, fold 8\n",
      "Score is 0.8541666666666667\n",
      "Rep 5, fold 9\n",
      "Score is 0.875\n",
      "Rep 5, fold 10\n",
      "Score is 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "all_accuracy = []\n",
    "\n",
    "dataset = \"Musk2\"\n",
    "\n",
    "for i in range(1,6):\n",
    "    for j in range(1, 11):\n",
    "        print(f\"Rep {i}, fold {j}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        (train_features,\n",
    "             train_labels,\n",
    "             train_bag_ids,\n",
    "             test_features,\n",
    "             test_labels,\n",
    "             test_bag_ids) = train_test_split(dataset, i, j, 1, fit_on_full = True)\n",
    "\n",
    "        model = PrototypeForest(size=8,\n",
    "                                max_depth=100,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_samples_split=4,\n",
    "                                prototype_count=1,\n",
    "                                early_stopping_round= 5,\n",
    "                                use_prototype_learner = False)\n",
    "\n",
    "        model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "        probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "        _, index  = np.unique(test_bag_ids, return_index=True)\n",
    "\n",
    "        score = roc_auc_score(test_labels[index], probas[index])\n",
    "        end_time = time.time()\n",
    "        all_accuracy.append(score)\n",
    "        print(f\"Score is {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98267672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8410714285714285"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_accuracy)/len(all_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b00abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_csv(\"./dataset_groups.csv\")\n",
    "\n",
    "group_id = 2\n",
    "\n",
    "datasets = groups[groups[\"Group\"] == int(group_id)][\"dataset\"].to_list()\n",
    "best_params = pd.read_csv(\"./best_params.csv\")\n",
    "\n",
    "check = os.listdir(\"./performance_linear\")\n",
    "ran_already = [x.split(\".\")[0] for x in check]\n",
    "datasets = list(set(datasets) - set(ran_already))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64007425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HermitWarbler',\n",
       " 'Harddrive1',\n",
       " 'Web4',\n",
       " 'Web2',\n",
       " 'SwainsonsThrush',\n",
       " 'Mutagenesis1',\n",
       " 'Web5',\n",
       " 'Newsgroups9',\n",
       " 'Web3',\n",
       " 'Newsgroups15',\n",
       " 'Newsgroups7',\n",
       " 'Web8',\n",
       " 'Red-breastedNuthatch',\n",
       " 'Newsgroups8',\n",
       " 'Tiger',\n",
       " 'Musk2',\n",
       " 'Newsgroups3']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed464805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best size is 100 and best depth is 4 and best var is 1.0 for dataset Mutagenesis1\n",
      "Rep 1, fold 1\n",
      "Score is 0.7243589743589743\n",
      "Rep 1, fold 2\n",
      "Score is 0.6282051282051282\n",
      "Rep 1, fold 3\n",
      "Score is 0.8846153846153847\n",
      "Rep 1, fold 4\n",
      "Score is 0.8141025641025641\n",
      "Rep 1, fold 5\n",
      "Score is 0.717948717948718\n",
      "Rep 1, fold 6\n",
      "Score is 0.6785714285714286\n",
      "Rep 1, fold 7\n",
      "Score is 0.9880952380952381\n",
      "Rep 1, fold 8\n",
      "Score is 0.5476190476190477\n",
      "Rep 1, fold 9\n",
      "Score is 0.8263888888888888\n",
      "Rep 1, fold 10\n",
      "Score is 0.625\n",
      "Rep 2, fold 1\n",
      "Score is 0.8846153846153846\n",
      "Rep 2, fold 2\n",
      "Score is 0.6794871794871795\n",
      "Rep 2, fold 3\n",
      "Score is 0.6666666666666667\n",
      "Rep 2, fold 4\n",
      "Score is 0.576923076923077\n",
      "Rep 2, fold 5\n",
      "Score is 0.8141025641025641\n",
      "Rep 2, fold 6\n",
      "Score is 0.6726190476190476\n",
      "Rep 2, fold 7\n",
      "Score is 0.8214285714285714\n",
      "Rep 2, fold 8\n",
      "Score is 0.8869047619047619\n",
      "Rep 2, fold 9\n",
      "Score is 0.9305555555555556\n",
      "Rep 2, fold 10\n",
      "Score is 0.5902777777777778\n",
      "Rep 3, fold 1\n",
      "Score is 0.858974358974359\n",
      "Rep 3, fold 2\n",
      "Score is 0.8525641025641026\n",
      "Rep 3, fold 3\n",
      "Score is 0.9166666666666667\n",
      "Rep 3, fold 4\n",
      "Score is 0.5192307692307693\n",
      "Rep 3, fold 5\n",
      "Score is 0.8205128205128207\n",
      "Rep 3, fold 6\n",
      "Score is 0.8988095238095237\n",
      "Rep 3, fold 7\n",
      "Score is 0.8273809523809523\n",
      "Rep 3, fold 8\n",
      "Score is 0.511904761904762\n",
      "Rep 3, fold 9\n",
      "Score is 0.7361111111111112\n",
      "Rep 3, fold 10\n",
      "Score is 0.6111111111111112\n",
      "Rep 4, fold 1\n",
      "Score is 0.8910256410256411\n",
      "Rep 4, fold 2\n",
      "Score is 0.7756410256410258\n",
      "Rep 4, fold 3\n",
      "Score is 0.858974358974359\n",
      "Rep 4, fold 4\n",
      "Score is 0.7051282051282052\n",
      "Rep 4, fold 5\n",
      "Score is 0.6666666666666667\n",
      "Rep 4, fold 6\n",
      "Score is 0.8452380952380951\n",
      "Rep 4, fold 7\n",
      "Score is 0.8035714285714286\n",
      "Rep 4, fold 8\n",
      "Score is 0.6071428571428571\n",
      "Rep 4, fold 9\n",
      "Score is 0.7916666666666667\n",
      "Rep 4, fold 10\n",
      "Score is 0.7361111111111112\n",
      "Rep 5, fold 1\n",
      "Score is 0.7051282051282052\n",
      "Rep 5, fold 2\n",
      "Score is 0.7692307692307693\n",
      "Rep 5, fold 3\n",
      "Score is 0.6923076923076923\n",
      "Rep 5, fold 4\n",
      "Score is 0.8333333333333335\n",
      "Rep 5, fold 5\n",
      "Score is 0.6474358974358975\n",
      "Rep 5, fold 6\n",
      "Score is 0.7678571428571428\n",
      "Rep 5, fold 7\n",
      "Score is 0.6964285714285715\n",
      "Rep 5, fold 8\n",
      "Score is 0.8333333333333334\n",
      "Rep 5, fold 9\n",
      "Score is 0.875\n",
      "Rep 5, fold 10\n",
      "Score is 0.7569444444444445\n",
      "Accuracy for Mutagenesis1 is 0.7553983516483517\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"Mutagenesis1\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    scores = []\n",
    "    info_list = []\n",
    "\n",
    "    PCA_vals = best_params[best_params[\"dataset\"] == dataset][\"PCA\"].values.tolist()\n",
    "    best_depth = best_params[best_params[\"dataset\"] == dataset][\"max_depth\"].values[0]\n",
    "    best_size = best_params[best_params[\"dataset\"] == dataset][\"ntree\"].values[0]\n",
    "\n",
    "    best_depth = 4\n",
    "    best_size = 100\n",
    "    \n",
    "    if(len(PCA_vals[0]) > 1):\n",
    "        PCA_vals = PCA_vals[0].split(\"-\")\n",
    "        PCA_vals = [float(x) for x in PCA_vals]\n",
    "    else:\n",
    "        PCA_vals = float(best_params[best_params[\"dataset\"] == dataset][\"PCA\"].values[0])\n",
    "    \n",
    "    if(isinstance(PCA_vals, list)):\n",
    "        for k in PCA_vals:\n",
    "            (train_features,\n",
    "                    train_labels,\n",
    "                    train_bag_ids,\n",
    "                    test_features,\n",
    "                    test_labels,\n",
    "                    test_bag_ids) = train_test_split(dataset, 5, 10, k, fit_on_full = False, custom=True)\n",
    "\n",
    "            model = PrototypeForest(size=best_size,\n",
    "                                    max_depth=best_depth,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    min_samples_split=4,\n",
    "                                    prototype_count=1,\n",
    "                                    early_stopping_round= 3,\n",
    "                                    use_prototype_learner = False)\n",
    "\n",
    "            model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "            probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "            score = roc_auc_score(test_labels, probas)\n",
    "            scores.append([k, score])\n",
    "    \n",
    "            df = pd.DataFrame(scores, columns = [\"variance\",\"score\"])\n",
    "            print(df)\n",
    "            best_row = df.iloc[df[\"score\"].argmax()]\n",
    "            best_var = best_row.get(\"variance\")\n",
    "    else:\n",
    "        best_var = PCA_vals\n",
    "\n",
    "\n",
    "    all_accuracy = []\n",
    "\n",
    "    print(f\"Best size is {best_size} and best depth is {best_depth} and best var is {best_var} for dataset {dataset}\")\n",
    "\n",
    "    for i in range(1,6):\n",
    "        for j in range(1, 11):\n",
    "            print(f\"Rep {i}, fold {j}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            (train_features,\n",
    "                 train_labels,\n",
    "                 train_bag_ids,\n",
    "                 test_features,\n",
    "                 test_labels,\n",
    "                 test_bag_ids) = train_test_split(dataset, i, j, best_var, fit_on_full = True)\n",
    "\n",
    "            model = PrototypeForest(size=best_size,\n",
    "                                    max_depth=best_depth,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    min_samples_split=4,\n",
    "                                    prototype_count=1,\n",
    "                                    early_stopping_round= 5,\n",
    "                                    use_prototype_learner = False)\n",
    "\n",
    "            model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "            probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "            _, index  = np.unique(test_bag_ids, return_index=True)\n",
    "\n",
    "            score = roc_auc_score(test_labels[index], probas[index])\n",
    "            end_time = time.time()\n",
    "            info_list_row = [dataset, i, j, best_size, best_depth, best_var, score, end_time - start_time]\n",
    "            info_list.append(info_list_row)\n",
    "            all_accuracy.append(score)\n",
    "            print(f\"Score is {score}\")\n",
    "\n",
    "    print(f\"Accuracy for {dataset} is {sum(all_accuracy)/len(all_accuracy)}\")\n",
    "    perf_df = pd.DataFrame(info_list, columns=[\"dataset\", \"rep\", \"fold\", \"best_size\", \"best_depth\", \"best_var\",  \"auc\", \"time\"])\n",
    "    perf_df.to_csv(f\"./performance_linear_new/{dataset}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4e85063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best size is 100 and best depth is 8 and best var is 1.0 for dataset HermitWarbler\n",
      "Rep 1, fold 1\n",
      "Score is 0.9107142857142857\n",
      "Rep 1, fold 2\n",
      "Score is 0.8005952380952381\n",
      "Rep 1, fold 3\n",
      "Score is 0.8482142857142857\n",
      "Rep 1, fold 4\n",
      "Score is 0.9421768707482994\n",
      "Rep 1, fold 5\n",
      "Score is 0.8945578231292517\n",
      "Rep 1, fold 6\n",
      "Score is 0.9064625850340137\n",
      "Rep 1, fold 7\n",
      "Score is 0.9693877551020409\n",
      "Rep 1, fold 8\n",
      "Score is 0.8571428571428572\n",
      "Rep 1, fold 9\n",
      "Score is 0.8993055555555557\n",
      "Rep 1, fold 10\n",
      "Score is 0.9878472222222222\n",
      "Rep 2, fold 1\n",
      "Score is 0.988095238095238\n",
      "Rep 2, fold 2\n",
      "Score is 0.9092261904761906\n",
      "Rep 2, fold 3\n",
      "Score is 0.8541666666666666\n",
      "Rep 2, fold 4\n",
      "Score is 0.8792517006802721\n",
      "Rep 2, fold 5\n",
      "Score is 0.9098639455782314\n",
      "Rep 2, fold 6\n",
      "Score is 0.7993197278911565\n",
      "Rep 2, fold 7\n",
      "Score is 0.9812925170068028\n",
      "Rep 2, fold 8\n",
      "Score is 0.9778911564625851\n",
      "Rep 2, fold 9\n",
      "Score is 0.8871527777777779\n",
      "Rep 2, fold 10\n",
      "Score is 0.9322916666666667\n",
      "Rep 3, fold 1\n",
      "Score is 0.90625\n",
      "Rep 3, fold 2\n",
      "Score is 0.8541666666666666\n",
      "Rep 3, fold 3\n",
      "Score is 0.8898809523809524\n",
      "Rep 3, fold 4\n",
      "Score is 0.9693877551020409\n",
      "Rep 3, fold 5\n",
      "Score is 0.7159863945578231\n",
      "Rep 3, fold 6\n",
      "Score is 0.8962585034013606\n",
      "Rep 3, fold 7\n",
      "Score is 0.9863945578231292\n",
      "Rep 3, fold 8\n",
      "Score is 0.9710884353741497\n",
      "Rep 3, fold 9\n",
      "Score is 0.9861111111111112\n",
      "Rep 3, fold 10\n",
      "Score is 0.96875\n",
      "Rep 4, fold 1\n",
      "Score is 0.9494047619047619\n",
      "Rep 4, fold 2\n",
      "Score is 0.9657738095238095\n",
      "Rep 4, fold 3\n",
      "Score is 0.9092261904761905\n",
      "Rep 4, fold 4\n",
      "Score is 0.8265306122448979\n",
      "Rep 4, fold 5\n",
      "Score is 0.9846938775510203\n",
      "Rep 4, fold 6\n",
      "Score is 0.9659863945578231\n",
      "Rep 4, fold 7\n",
      "Score is 0.9761904761904763\n",
      "Rep 4, fold 8\n",
      "Score is 0.9761904761904762\n",
      "Rep 4, fold 9\n",
      "Score is 0.875\n",
      "Rep 4, fold 10\n",
      "Score is 0.9444444444444445\n",
      "Rep 5, fold 1\n",
      "Score is 0.9032738095238095\n",
      "Rep 5, fold 2\n",
      "Score is 0.6309523809523808\n",
      "Rep 5, fold 3\n",
      "Score is 0.912202380952381\n",
      "Rep 5, fold 4\n",
      "Score is 0.9659863945578231\n",
      "Rep 5, fold 5\n",
      "Score is 0.8078231292517006\n",
      "Rep 5, fold 6\n",
      "Score is 0.977891156462585\n",
      "Rep 5, fold 7\n",
      "Score is 0.8877551020408164\n",
      "Rep 5, fold 8\n",
      "Score is 0.9115646258503403\n",
      "Rep 5, fold 9\n",
      "Score is 0.9947916666666667\n",
      "Rep 5, fold 10\n",
      "Score is 0.9652777777777778\n",
      "Accuracy for HermitWarbler is 0.9122037981859408\n",
      "Best size is 100 and best depth is 8 and best var is 1.0 for dataset Harddrive1\n",
      "Rep 1, fold 1\n",
      "Score is 1.0\n",
      "Rep 1, fold 2\n",
      "Score is 0.9663742690058479\n",
      "Rep 1, fold 3\n",
      "Score is 1.0\n",
      "Rep 1, fold 4\n",
      "Score is 0.9941520467836257\n",
      "Rep 1, fold 5\n",
      "Score is 0.9970760233918129\n",
      "Rep 1, fold 6\n",
      "Score is 0.9678362573099414\n",
      "Rep 1, fold 7\n",
      "Score is 1.0\n",
      "Rep 1, fold 8\n",
      "Score is 1.0\n",
      "Rep 1, fold 9\n",
      "Score is 0.9692982456140351\n",
      "Rep 1, fold 10\n",
      "Score is 0.9907120743034055\n",
      "Rep 2, fold 1\n",
      "Score is 0.9970588235294118\n",
      "Rep 2, fold 2\n",
      "Score is 0.9926900584795322\n",
      "Rep 2, fold 3\n",
      "Score is 0.9970760233918128\n",
      "Rep 2, fold 4\n",
      "Score is 1.0\n",
      "Rep 2, fold 5\n",
      "Score is 0.9649122807017544\n",
      "Rep 2, fold 6\n",
      "Score is 0.9970760233918129\n",
      "Rep 2, fold 7\n",
      "Score is 1.0\n",
      "Rep 2, fold 8\n",
      "Score is 0.9678362573099415\n",
      "Rep 2, fold 9\n",
      "Score is 0.9634502923976609\n",
      "Rep 2, fold 10\n",
      "Score is 0.9969040247678018\n",
      "Rep 3, fold 1\n",
      "Score is 0.9970588235294118\n",
      "Rep 3, fold 2\n",
      "Score is 0.9692982456140351\n",
      "Rep 3, fold 3\n",
      "Score is 0.9912280701754387\n",
      "Rep 3, fold 4\n",
      "Score is 1.0\n",
      "Rep 3, fold 5\n",
      "Score is 1.0\n",
      "Rep 3, fold 6\n",
      "Score is 1.0\n",
      "Rep 3, fold 7\n",
      "Score is 1.0\n",
      "Rep 3, fold 8\n",
      "Score is 0.9619883040935673\n",
      "Rep 3, fold 9\n",
      "Score is 1.0\n",
      "Rep 3, fold 10\n",
      "Score is 0.9643962848297213\n",
      "Rep 4, fold 1\n",
      "Score is 0.9411764705882352\n",
      "Rep 4, fold 2\n",
      "Score is 1.0\n",
      "Rep 4, fold 3\n",
      "Score is 1.0\n",
      "Rep 4, fold 4\n",
      "Score is 1.0\n",
      "Rep 4, fold 5\n",
      "Score is 0.9912280701754386\n",
      "Rep 4, fold 6\n",
      "Score is 0.9941520467836258\n",
      "Rep 4, fold 7\n",
      "Score is 1.0\n",
      "Rep 4, fold 8\n",
      "Score is 0.9970760233918129\n",
      "Rep 4, fold 9\n",
      "Score is 0.9722222222222221\n",
      "Rep 4, fold 10\n",
      "Score is 0.9938080495356036\n",
      "Rep 5, fold 1\n",
      "Score is 0.9941176470588234\n",
      "Rep 5, fold 2\n",
      "Score is 1.0\n",
      "Rep 5, fold 3\n",
      "Score is 0.9692982456140351\n",
      "Rep 5, fold 4\n",
      "Score is 0.9970760233918129\n",
      "Rep 5, fold 5\n",
      "Score is 0.9912280701754386\n",
      "Rep 5, fold 6\n",
      "Score is 0.9546783625730992\n",
      "Rep 5, fold 7\n",
      "Score is 1.0\n",
      "Rep 5, fold 8\n",
      "Score is 1.0\n",
      "Rep 5, fold 9\n",
      "Score is 0.9970760233918129\n",
      "Rep 5, fold 10\n",
      "Score is 0.9705882352941175\n",
      "Accuracy for Harddrive1 is 0.9882029583763327\n",
      "   variance  score\n",
      "0       0.5    1.0\n",
      "   variance     score\n",
      "0       0.5  1.000000\n",
      "1       0.6  0.406835\n",
      "   variance     score\n",
      "0       0.5  1.000000\n",
      "1       0.6  0.406835\n",
      "2       0.7  0.768293\n",
      "   variance     score\n",
      "0       0.5  1.000000\n",
      "1       0.6  0.406835\n",
      "2       0.7  0.768293\n",
      "3       0.8  0.878049\n",
      "   variance     score\n",
      "0       0.5  1.000000\n",
      "1       0.6  0.406835\n",
      "2       0.7  0.768293\n",
      "3       0.8  0.878049\n",
      "4       0.9  0.890244\n",
      "   variance     score\n",
      "0       0.5  1.000000\n",
      "1       0.6  0.406835\n",
      "2       0.7  0.768293\n",
      "3       0.8  0.878049\n",
      "4       0.9  0.890244\n",
      "5       1.0  0.621951\n",
      "Best size is 100 and best depth is 12 and best var is 0.5 for dataset Web4\n",
      "Rep 1, fold 1\n",
      "Score is 0.75\n",
      "Rep 1, fold 2\n",
      "Score is 0.8333333333333334\n",
      "Rep 1, fold 3\n",
      "Score is 0.6666666666666666\n",
      "Rep 1, fold 4\n",
      "Score is 0.7916666666666666\n",
      "Rep 1, fold 5\n",
      "Score is 0.8333333333333333\n",
      "Rep 1, fold 6\n",
      "Score is 0.8\n",
      "Rep 1, fold 7\n",
      "Score is 0.7\n",
      "Rep 1, fold 8\n",
      "Score is 1.0\n",
      "Rep 1, fold 9\n",
      "Score is 0.4\n",
      "Rep 1, fold 10\n",
      "Score is 1.0\n",
      "Rep 2, fold 1\n",
      "Score is 0.7083333333333334\n",
      "Rep 2, fold 2\n",
      "Score is 0.875\n",
      "Rep 2, fold 3\n",
      "Score is 0.9166666666666667\n",
      "Rep 2, fold 4\n",
      "Score is 0.875\n",
      "Rep 2, fold 5\n",
      "Score is 0.6666666666666666\n",
      "Rep 2, fold 6\n",
      "Score is 1.0\n",
      "Rep 2, fold 7\n",
      "Score is 1.0\n",
      "Rep 2, fold 8\n",
      "Score is 0.75\n",
      "Rep 2, fold 9\n",
      "Score is 0.5\n",
      "Rep 2, fold 10\n",
      "Score is 0.15000000000000002\n",
      "Rep 3, fold 1\n",
      "Score is 0.9166666666666667\n",
      "Rep 3, fold 2\n",
      "Score is 1.0\n",
      "Rep 3, fold 3\n",
      "Score is 0.625\n",
      "Rep 3, fold 4\n",
      "Score is 0.125\n",
      "Rep 3, fold 5\n",
      "Score is 0.75\n",
      "Rep 3, fold 6\n",
      "Score is 0.7\n",
      "Rep 3, fold 7\n",
      "Score is 0.4\n",
      "Rep 3, fold 8\n",
      "Score is 0.65\n",
      "Rep 3, fold 9\n",
      "Score is 1.0\n",
      "Rep 3, fold 10\n",
      "Score is 1.0\n",
      "Rep 4, fold 1\n",
      "Score is 0.6666666666666667\n",
      "Rep 4, fold 2\n",
      "Score is 0.625\n",
      "Rep 4, fold 3\n",
      "Score is 0.75\n",
      "Rep 4, fold 4\n",
      "Score is 0.41666666666666663\n",
      "Rep 4, fold 5\n",
      "Score is 1.0\n",
      "Rep 4, fold 6\n",
      "Score is 0.9\n",
      "Rep 4, fold 7\n",
      "Score is 0.7\n",
      "Rep 4, fold 8\n",
      "Score is 0.7\n",
      "Rep 4, fold 9\n",
      "Score is 1.0\n",
      "Rep 4, fold 10\n",
      "Score is 1.0\n",
      "Rep 5, fold 1\n",
      "Score is 0.5833333333333334\n",
      "Rep 5, fold 2\n",
      "Score is 1.0\n",
      "Rep 5, fold 3\n",
      "Score is 0.6666666666666666\n",
      "Rep 5, fold 4\n",
      "Score is 0.5\n",
      "Rep 5, fold 5\n",
      "Score is 0.25\n",
      "Rep 5, fold 6\n",
      "Score is 0.7\n",
      "Rep 5, fold 7\n",
      "Score is 1.0\n",
      "Rep 5, fold 8\n",
      "Score is 0.9\n",
      "Rep 5, fold 9\n",
      "Score is 0.7\n",
      "Rep 5, fold 10\n",
      "Score is 1.0\n",
      "Accuracy for Web4 is 0.7488333333333332\n",
      "   variance     score\n",
      "0       0.5  0.118182\n",
      "   variance     score\n",
      "0       0.5  0.118182\n",
      "1       0.6  0.118182\n",
      "   variance     score\n",
      "0       0.5  0.118182\n",
      "1       0.6  0.118182\n",
      "2       0.7  0.500000\n",
      "   variance     score\n",
      "0       0.5  0.118182\n",
      "1       0.6  0.118182\n",
      "2       0.7  0.500000\n",
      "3       0.8  0.500000\n",
      "   variance     score\n",
      "0       0.5  0.118182\n",
      "1       0.6  0.118182\n",
      "2       0.7  0.500000\n",
      "3       0.8  0.500000\n",
      "4       0.9  0.816092\n",
      "   variance     score\n",
      "0       0.5  0.118182\n",
      "1       0.6  0.118182\n",
      "2       0.7  0.500000\n",
      "3       0.8  0.500000\n",
      "4       0.9  0.816092\n",
      "5       1.0  0.718391\n",
      "Best size is 100 and best depth is 12 and best var is 0.9 for dataset Web2\n",
      "Rep 1, fold 1\n",
      "Score is 0.75\n",
      "Rep 1, fold 2\n",
      "Score is 0.5833333333333334\n",
      "Rep 1, fold 3\n",
      "Score is 0.5\n",
      "Rep 1, fold 4\n",
      "Score is 0.5\n",
      "Rep 1, fold 5\n",
      "Score is 0.5\n",
      "Rep 1, fold 6\n",
      "Score is 0.5\n",
      "Rep 1, fold 7\n",
      "Score is 0.5\n",
      "Rep 1, fold 8\n",
      "Score is 0.3\n",
      "Rep 1, fold 9\n",
      "Score is 0.8333333333333334\n",
      "Rep 1, fold 10\n",
      "Score is 0.4166666666666667\n",
      "Rep 2, fold 1\n",
      "Score is 0.5\n",
      "Rep 2, fold 2\n",
      "Score is 0.5\n",
      "Rep 2, fold 3\n",
      "Score is 0.625\n",
      "Rep 2, fold 4\n",
      "Score is 0.5\n",
      "Rep 2, fold 5\n",
      "Score is 0.5833333333333334\n",
      "Rep 2, fold 6\n",
      "Score is 0.4\n",
      "Rep 2, fold 7\n",
      "Score is 0.4\n",
      "Rep 2, fold 8\n",
      "Score is 0.5\n",
      "Rep 2, fold 9\n",
      "Score is 0.5\n",
      "Rep 2, fold 10\n",
      "Score is 0.33333333333333337\n",
      "Rep 3, fold 1\n",
      "Score is 0.5\n",
      "Rep 3, fold 2\n",
      "Score is 0.5\n",
      "Rep 3, fold 3\n",
      "Score is 0.25\n",
      "Rep 3, fold 4\n",
      "Score is 0.5\n",
      "Rep 3, fold 5\n",
      "Score is 0.5\n",
      "Rep 3, fold 6\n",
      "Score is 0.3\n",
      "Rep 3, fold 7\n",
      "Score is 0.5\n",
      "Rep 3, fold 8\n",
      "Score is 0.5\n",
      "Rep 3, fold 9\n",
      "Score is 0.33333333333333337\n",
      "Rep 3, fold 10\n",
      "Score is 1.0\n",
      "Rep 4, fold 1\n",
      "Score is 0.5\n",
      "Rep 4, fold 2\n",
      "Score is 0.5\n",
      "Rep 4, fold 3\n",
      "Score is 0.33333333333333337\n",
      "Rep 4, fold 4\n",
      "Score is 0.5416666666666666\n",
      "Rep 4, fold 5\n",
      "Score is 0.5\n",
      "Rep 4, fold 6\n",
      "Score is 0.5\n",
      "Rep 4, fold 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.3\n",
      "Rep 4, fold 8\n",
      "Score is 0.5\n",
      "Rep 4, fold 9\n",
      "Score is 0.5\n",
      "Rep 4, fold 10\n",
      "Score is 0.33333333333333337\n",
      "Rep 5, fold 1\n",
      "Score is 0.5\n",
      "Rep 5, fold 2\n",
      "Score is 0.5\n",
      "Rep 5, fold 3\n",
      "Score is 0.5\n",
      "Rep 5, fold 4\n",
      "Score is 0.7083333333333334\n",
      "Rep 5, fold 5\n",
      "Score is 0.16666666666666669\n",
      "Rep 5, fold 6\n",
      "Score is 0.4\n",
      "Rep 5, fold 7\n",
      "Score is 0.5\n",
      "Rep 5, fold 8\n",
      "Score is 0.5\n",
      "Rep 5, fold 9\n",
      "Score is 0.4166666666666667\n",
      "Rep 5, fold 10\n",
      "Score is 0.33333333333333337\n",
      "Accuracy for Web2 is 0.48283333333333334\n",
      "Best size is 100 and best depth is 8 and best var is 1.0 for dataset SwainsonsThrush\n",
      "Rep 1, fold 1\n",
      "Score is 0.7287234042553191\n",
      "Rep 1, fold 2\n",
      "Score is 0.4787234042553192\n",
      "Rep 1, fold 3\n",
      "Score is 0.723404255319149\n",
      "Rep 1, fold 4\n",
      "Score is 0.6156914893617021\n",
      "Rep 1, fold 5\n",
      "Score is 0.8683510638297872\n",
      "Rep 1, fold 6\n",
      "Score is 0.6143617021276595\n",
      "Rep 1, fold 7\n",
      "Score is 0.553191489361702\n",
      "Rep 1, fold 8\n",
      "Score is 0.6728723404255319\n",
      "Rep 1, fold 9\n",
      "Score is 0.7241847826086957\n",
      "Rep 1, fold 10\n",
      "Score is 0.7537993920972644\n",
      "Rep 2, fold 1\n",
      "Score is 0.8045212765957447\n",
      "Rep 2, fold 2\n",
      "Score is 0.5970744680851064\n",
      "Rep 2, fold 3\n",
      "Score is 0.8045212765957447\n",
      "Rep 2, fold 4\n",
      "Score is 0.6662234042553192\n",
      "Rep 2, fold 5\n",
      "Score is 0.75\n",
      "Rep 2, fold 6\n",
      "Score is 0.6170212765957447\n",
      "Rep 2, fold 7\n",
      "Score is 0.6156914893617021\n",
      "Rep 2, fold 8\n",
      "Score is 0.8630319148936171\n",
      "Rep 2, fold 9\n",
      "Score is 0.6141304347826086\n",
      "Rep 2, fold 10\n",
      "Score is 0.4787234042553192\n",
      "Rep 3, fold 1\n",
      "Score is 0.5518617021276595\n",
      "Rep 3, fold 2\n",
      "Score is 0.7938829787234043\n",
      "Rep 3, fold 3\n",
      "Score is 0.7353723404255319\n",
      "Rep 3, fold 4\n",
      "Score is 0.6781914893617021\n",
      "Rep 3, fold 5\n",
      "Score is 0.7074468085106383\n",
      "Rep 3, fold 6\n",
      "Score is 0.6183510638297872\n",
      "Rep 3, fold 7\n",
      "Score is 0.625\n",
      "Rep 3, fold 8\n",
      "Score is 0.7393617021276596\n",
      "Rep 3, fold 9\n",
      "Score is 0.625\n",
      "Rep 3, fold 10\n",
      "Score is 0.6778115501519757\n",
      "Rep 4, fold 1\n",
      "Score is 0.553191489361702\n",
      "Rep 4, fold 2\n",
      "Score is 0.8125\n",
      "Rep 4, fold 3\n",
      "Score is 0.8085106382978724\n",
      "Rep 4, fold 4\n",
      "Score is 0.6170212765957447\n",
      "Rep 4, fold 5\n",
      "Score is 0.4574468085106383\n",
      "Rep 4, fold 6\n",
      "Score is 0.6170212765957447\n",
      "Rep 4, fold 7\n",
      "Score is 0.7220744680851064\n",
      "Rep 4, fold 8\n",
      "Score is 0.5438829787234043\n",
      "Rep 4, fold 9\n",
      "Score is 0.6875\n",
      "Rep 4, fold 10\n",
      "Score is 0.6246200607902735\n",
      "Rep 5, fold 1\n",
      "Score is 0.5518617021276595\n",
      "Rep 5, fold 2\n",
      "Score is 0.625\n",
      "Rep 5, fold 3\n",
      "Score is 0.6050531914893618\n",
      "Rep 5, fold 4\n",
      "Score is 0.7992021276595745\n",
      "Rep 5, fold 5\n",
      "Score is 0.625\n",
      "Rep 5, fold 6\n",
      "Score is 0.7420212765957447\n",
      "Rep 5, fold 7\n",
      "Score is 0.553191489361702\n",
      "Rep 5, fold 8\n",
      "Score is 0.6476063829787233\n",
      "Rep 5, fold 9\n",
      "Score is 0.7404891304347826\n",
      "Rep 5, fold 10\n",
      "Score is 0.8267477203647416\n",
      "Accuracy for SwainsonsThrush is 0.6691292784458834\n",
      "Best size is 100 and best depth is 8 and best var is 1.0 for dataset Mutagenesis1\n",
      "Rep 1, fold 1\n",
      "Score is 0.7243589743589743\n",
      "Rep 1, fold 2\n",
      "Score is 0.6410256410256411\n",
      "Rep 1, fold 3\n",
      "Score is 0.891025641025641\n",
      "Rep 1, fold 4\n",
      "Score is 0.7884615384615384\n",
      "Rep 1, fold 5\n",
      "Score is 0.7051282051282052\n",
      "Rep 1, fold 6\n",
      "Score is 0.7083333333333334\n",
      "Rep 1, fold 7\n",
      "Score is 1.0\n",
      "Rep 1, fold 8\n",
      "Score is 0.5178571428571429\n",
      "Rep 1, fold 9\n",
      "Score is 0.8333333333333333\n",
      "Rep 1, fold 10\n",
      "Score is 0.6597222222222223\n",
      "Rep 2, fold 1\n",
      "Score is 0.9102564102564104\n",
      "Rep 2, fold 2\n",
      "Score is 0.6923076923076923\n",
      "Rep 2, fold 3\n",
      "Score is 0.6538461538461539\n",
      "Rep 2, fold 4\n",
      "Score is 0.5705128205128205\n",
      "Rep 2, fold 5\n",
      "Score is 0.8653846153846154\n",
      "Rep 2, fold 6\n",
      "Score is 0.6726190476190477\n",
      "Rep 2, fold 7\n",
      "Score is 0.8809523809523809\n",
      "Rep 2, fold 8\n",
      "Score is 0.8809523809523809\n",
      "Rep 2, fold 9\n",
      "Score is 0.9166666666666667\n",
      "Rep 2, fold 10\n",
      "Score is 0.5902777777777778\n",
      "Rep 3, fold 1\n",
      "Score is 0.858974358974359\n",
      "Rep 3, fold 2\n",
      "Score is 0.8782051282051283\n",
      "Rep 3, fold 3\n",
      "Score is 0.9487179487179488\n",
      "Rep 3, fold 4\n",
      "Score is 0.5448717948717949\n",
      "Rep 3, fold 5\n",
      "Score is 0.8205128205128207\n",
      "Rep 3, fold 6\n",
      "Score is 0.8928571428571428\n",
      "Rep 3, fold 7\n",
      "Score is 0.7916666666666666\n",
      "Rep 3, fold 8\n",
      "Score is 0.5714285714285714\n",
      "Rep 3, fold 9\n",
      "Score is 0.7361111111111112\n",
      "Rep 3, fold 10\n",
      "Score is 0.5833333333333333\n",
      "Rep 4, fold 1\n",
      "Score is 0.8269230769230769\n",
      "Rep 4, fold 2\n",
      "Score is 0.7628205128205129\n",
      "Rep 4, fold 3\n",
      "Score is 0.858974358974359\n",
      "Rep 4, fold 4\n",
      "Score is 0.6923076923076924\n",
      "Rep 4, fold 5\n",
      "Score is 0.7051282051282052\n",
      "Rep 4, fold 6\n",
      "Score is 0.8630952380952381\n",
      "Rep 4, fold 7\n",
      "Score is 0.8452380952380952\n",
      "Rep 4, fold 8\n",
      "Score is 0.6071428571428572\n",
      "Rep 4, fold 9\n",
      "Score is 0.8055555555555557\n",
      "Rep 4, fold 10\n",
      "Score is 0.7222222222222222\n",
      "Rep 5, fold 1\n",
      "Score is 0.6666666666666667\n",
      "Rep 5, fold 2\n",
      "Score is 0.7564102564102565\n",
      "Rep 5, fold 3\n",
      "Score is 0.717948717948718\n",
      "Rep 5, fold 4\n",
      "Score is 0.8333333333333334\n",
      "Rep 5, fold 5\n",
      "Score is 0.6153846153846154\n",
      "Rep 5, fold 6\n",
      "Score is 0.7619047619047619\n",
      "Rep 5, fold 7\n",
      "Score is 0.6845238095238095\n",
      "Rep 5, fold 8\n",
      "Score is 0.8452380952380952\n",
      "Rep 5, fold 9\n",
      "Score is 0.9027777777777778\n",
      "Rep 5, fold 10\n",
      "Score is 0.7777777777777778\n",
      "Accuracy for Mutagenesis1 is 0.7596214896214897\n",
      "   variance     score\n",
      "0       0.5  0.203704\n",
      "   variance     score\n",
      "0       0.5  0.203704\n",
      "1       0.6  0.203704\n",
      "   variance     score\n",
      "0       0.5  0.203704\n",
      "1       0.6  0.203704\n",
      "2       0.7  0.203704\n",
      "   variance     score\n",
      "0       0.5  0.203704\n",
      "1       0.6  0.203704\n",
      "2       0.7  0.203704\n",
      "3       0.8  0.253669\n",
      "   variance     score\n",
      "0       0.5  0.203704\n",
      "1       0.6  0.203704\n",
      "2       0.7  0.203704\n",
      "3       0.8  0.253669\n",
      "4       0.9  0.203704\n",
      "   variance     score\n",
      "0       0.5  0.203704\n",
      "1       0.6  0.203704\n",
      "2       0.7  0.203704\n",
      "3       0.8  0.253669\n",
      "4       0.9  0.203704\n",
      "5       1.0  0.081237\n",
      "Best size is 100 and best depth is 12 and best var is 0.8 for dataset Web5\n",
      "Rep 1, fold 1\n",
      "Score is 0.42857142857142855\n",
      "Rep 1, fold 2\n",
      "Score is 0.7083333333333334\n",
      "Rep 1, fold 3\n",
      "Score is 0.5416666666666666\n",
      "Rep 1, fold 4\n",
      "Score is 0.4166666666666667\n",
      "Rep 1, fold 5\n",
      "Score is 0.3333333333333333\n",
      "Rep 1, fold 6\n",
      "Score is 0.4166666666666667\n",
      "Rep 1, fold 7\n",
      "Score is 0.3333333333333333\n",
      "Rep 1, fold 8\n",
      "Score is 0.5\n",
      "Rep 1, fold 9\n",
      "Score is 1.0\n",
      "Rep 1, fold 10\n",
      "Score is 1.0\n",
      "Rep 2, fold 1\n",
      "Score is 0.35714285714285715\n",
      "Rep 2, fold 2\n",
      "Score is 0.625\n",
      "Rep 2, fold 3\n",
      "Score is 0.75\n",
      "Rep 2, fold 4\n",
      "Score is 0.45833333333333337\n",
      "Rep 2, fold 5\n",
      "Score is 0.75\n",
      "Rep 2, fold 6\n",
      "Score is 0.3333333333333333\n",
      "Rep 2, fold 7\n",
      "Score is 0.4166666666666667\n",
      "Rep 2, fold 8\n",
      "Score is 0.4166666666666667\n",
      "Rep 2, fold 9\n",
      "Score is 0.3333333333333333\n",
      "Rep 2, fold 10\n",
      "Score is 0.9166666666666667\n",
      "Rep 3, fold 1\n",
      "Score is 1.0\n",
      "Rep 3, fold 2\n",
      "Score is 0.5\n",
      "Rep 3, fold 3\n",
      "Score is 0.5\n",
      "Rep 3, fold 4\n",
      "Score is 0.4166666666666667\n",
      "Rep 3, fold 5\n",
      "Score is 0.5\n",
      "Rep 3, fold 6\n",
      "Score is 0.4166666666666667\n",
      "Rep 3, fold 7\n",
      "Score is 1.0\n",
      "Rep 3, fold 8\n",
      "Score is 0.25\n",
      "Rep 3, fold 9\n",
      "Score is 0.4166666666666667\n",
      "Rep 3, fold 10\n",
      "Score is 0.5\n",
      "Rep 4, fold 1\n",
      "Score is 0.35714285714285715\n",
      "Rep 4, fold 2\n",
      "Score is 0.4166666666666667\n",
      "Rep 4, fold 3\n",
      "Score is 0.5\n",
      "Rep 4, fold 4\n",
      "Score is 0.41666666666666663\n",
      "Rep 4, fold 5\n",
      "Score is 0.75\n",
      "Rep 4, fold 6\n",
      "Score is 0.3333333333333333\n",
      "Rep 4, fold 7\n",
      "Score is 0.25\n",
      "Rep 4, fold 8\n",
      "Score is 0.5\n",
      "Rep 4, fold 9\n",
      "Score is 1.0\n",
      "Rep 4, fold 10\n",
      "Score is 0.25\n",
      "Rep 5, fold 1\n",
      "Score is 0.2857142857142857\n",
      "Rep 5, fold 2\n",
      "Score is 0.3333333333333333\n",
      "Rep 5, fold 3\n",
      "Score is 0.75\n",
      "Rep 5, fold 4\n",
      "Score is 0.5\n",
      "Rep 5, fold 5\n",
      "Score is 0.75\n",
      "Rep 5, fold 6\n",
      "Score is 0.4166666666666667\n",
      "Rep 5, fold 7\n",
      "Score is 0.3333333333333333\n",
      "Rep 5, fold 8\n",
      "Score is 1.0\n",
      "Rep 5, fold 9\n",
      "Score is 0.4166666666666667\n",
      "Rep 5, fold 10\n",
      "Score is 0.16666666666666666\n",
      "Accuracy for Web5 is 0.5252380952380953\n",
      "Best size is 100 and best depth is 8 and best var is 1.0 for dataset Newsgroups9\n",
      "Rep 1, fold 1\n",
      "Score is 0.9\n",
      "Rep 1, fold 2\n",
      "Score is 0.72\n",
      "Rep 1, fold 3\n",
      "Score is 0.92\n",
      "Rep 1, fold 4\n",
      "Score is 0.8400000000000001\n",
      "Rep 1, fold 5\n",
      "Score is 1.0\n",
      "Rep 1, fold 6\n",
      "Score is 0.8400000000000001\n",
      "Rep 1, fold 7\n",
      "Score is 0.9600000000000001\n",
      "Rep 1, fold 8\n",
      "Score is 1.0\n",
      "Rep 1, fold 9\n",
      "Score is 0.8600000000000001\n",
      "Rep 1, fold 10\n",
      "Score is 0.72\n",
      "Rep 2, fold 1\n",
      "Score is 1.0\n",
      "Rep 2, fold 2\n",
      "Score is 0.8600000000000001\n",
      "Rep 2, fold 3\n",
      "Score is 0.8400000000000001\n",
      "Rep 2, fold 4\n",
      "Score is 1.0\n",
      "Rep 2, fold 5\n",
      "Score is 0.8600000000000001\n",
      "Rep 2, fold 6\n",
      "Score is 0.8\n",
      "Rep 2, fold 7\n",
      "Score is 1.0\n",
      "Rep 2, fold 8\n",
      "Score is 0.9199999999999999\n",
      "Rep 2, fold 9\n",
      "Score is 1.0\n",
      "Rep 2, fold 10\n",
      "Score is 0.7000000000000002\n",
      "Rep 3, fold 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-85a9aa69b687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                     use_prototype_learner = False)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bag_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_bag_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-05d34a5efa13>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, labels, bag_ids)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mearly_stopping_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping_round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             )\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbag_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbag_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbag_bag_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-018740a4b7cc>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, labels, bag_ids)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredictSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-018740a4b7cc>\u001b[0m in \u001b[0;36mbuildDT\u001b[0;34m(self, features, labels, bag_ids, node)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_ids_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_ids_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-018740a4b7cc>\u001b[0m in \u001b[0;36mbuildDT\u001b[0;34m(self, features, labels, bag_ids, node)\u001b[0m\n\u001b[1;32m    154\u001b[0m              \u001b[0mlabels_right\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m              \u001b[0mbag_ids_left\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m              \u001b[0mbag_ids_right\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcBestSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                                                  \u001b[0mfeatures_updated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-018740a4b7cc>\u001b[0m in \u001b[0;36mcalcBestSplit\u001b[0;34m(self, features, features_via_prototype, labels, bag_ids)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_via_prototype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    756\u001b[0m             iprint = [-1, 50, 1, 100, 101][\n\u001b[1;32m    757\u001b[0m                 np.searchsorted(np.array([0, 1, 2, 3]), verbose)]\n\u001b[0;32m--> 758\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    617\u001b[0m                                   **options)\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Logistic loss is the negative of the log of the logistic function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mlog_logistic\u001b[0;34m(X, out)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m     \u001b[0m_log_logistic_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_1d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    scores = []\n",
    "    info_list = []\n",
    "\n",
    "    PCA_vals = best_params[best_params[\"dataset\"] == dataset][\"PCA\"].values.tolist()\n",
    "    best_depth = best_params[best_params[\"dataset\"] == dataset][\"max_depth\"].values[0]\n",
    "    best_size = best_params[best_params[\"dataset\"] == dataset][\"ntree\"].values[0]\n",
    "\n",
    "    if(len(PCA_vals[0]) > 1):\n",
    "        PCA_vals = PCA_vals[0].split(\"-\")\n",
    "        PCA_vals = [float(x) for x in PCA_vals]\n",
    "    else:\n",
    "        PCA_vals = float(best_params[best_params[\"dataset\"] == dataset][\"PCA\"].values[0])\n",
    "    \n",
    "    if(isinstance(PCA_vals, list)):\n",
    "        for k in PCA_vals:\n",
    "            (train_features,\n",
    "                    train_labels,\n",
    "                    train_bag_ids,\n",
    "                    test_features,\n",
    "                    test_labels,\n",
    "                    test_bag_ids) = train_test_split(dataset, 5, 10, k, fit_on_full = False, custom=True)\n",
    "\n",
    "            model = PrototypeForest(size=best_size,\n",
    "                                    max_depth=best_depth,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    min_samples_split=4,\n",
    "                                    prototype_count=1,\n",
    "                                    early_stopping_round= 3,\n",
    "                                    use_prototype_learner = False)\n",
    "\n",
    "            model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "            probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "            score = roc_auc_score(test_labels, probas)\n",
    "            scores.append([k, score])\n",
    "    \n",
    "            df = pd.DataFrame(scores, columns = [\"variance\",\"score\"])\n",
    "            print(df)\n",
    "            best_row = df.iloc[df[\"score\"].argmax()]\n",
    "            best_var = best_row.get(\"variance\")\n",
    "    else:\n",
    "        best_var = PCA_vals\n",
    "\n",
    "\n",
    "    all_accuracy = []\n",
    "\n",
    "    print(f\"Best size is {best_size} and best depth is {best_depth} and best var is {best_var} for dataset {dataset}\")\n",
    "\n",
    "    for i in range(1,6):\n",
    "        for j in range(1, 11):\n",
    "            print(f\"Rep {i}, fold {j}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            (train_features,\n",
    "                 train_labels,\n",
    "                 train_bag_ids,\n",
    "                 test_features,\n",
    "                 test_labels,\n",
    "                 test_bag_ids) = train_test_split(dataset, i, j, best_var, fit_on_full = True)\n",
    "\n",
    "            model = PrototypeForest(size=best_size,\n",
    "                                    max_depth=best_depth,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    min_samples_split=4,\n",
    "                                    prototype_count=1,\n",
    "                                    early_stopping_round= 5,\n",
    "                                    use_prototype_learner = False)\n",
    "\n",
    "            model.fit(train_features, train_labels, train_bag_ids)\n",
    "\n",
    "            probas = model.predict_proba(test_features, test_bag_ids)\n",
    "\n",
    "            _, index  = np.unique(test_bag_ids, return_index=True)\n",
    "\n",
    "            score = roc_auc_score(test_labels[index], probas[index])\n",
    "            end_time = time.time()\n",
    "            info_list_row = [dataset, i, j, best_size, best_depth, best_var, score, end_time - start_time]\n",
    "            info_list.append(info_list_row)\n",
    "            all_accuracy.append(score)\n",
    "            print(f\"Score is {score}\")\n",
    "\n",
    "    print(f\"Accuracy for {dataset} is {sum(all_accuracy)/len(all_accuracy)}\")\n",
    "    perf_df = pd.DataFrame(info_list, columns=[\"dataset\", \"rep\", \"fold\", \"best_size\", \"best_depth\", \"best_var\",  \"auc\", \"time\"])\n",
    "    perf_df.to_csv(f\"./performance_linear/{dataset}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
